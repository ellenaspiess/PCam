{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe46bbb",
   "metadata": {},
   "source": [
    "# ResNet18 Transfer Learning on PCam\n",
    "\n",
    "In this notebook I explore transfer learning with ResNet18 on the PatchCamelyon (PCam) dataset.\n",
    "\n",
    "Goals:\n",
    "- Use the same PCam dataloaders and preprocessing as for the SmallCNN.\n",
    "- Compare different transfer learning modes:\n",
    "  - **frozen**: only the final classification head is trainable\n",
    "  - **partial**: last ResNet block + head are trainable\n",
    "- Evaluate models using **AUROC** and **AUPRC** on the validation set.\n",
    "- Prepare results for later comparison with the SmallCNN notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4006c517",
   "metadata": {},
   "source": [
    "## 1) Setup: imports, project root, device, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04709753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/ellenaspiess/Documents/PCam_Project/PCam\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Make sure we can import from the project src/ folder\n",
    "# -------------------------------------------------------------------\n",
    "ROOT = Path().resolve()\n",
    "if not (ROOT / \"src\").exists():\n",
    "    # If the notebook is inside notebooks/, go one level up\n",
    "    ROOT = ROOT.parent\n",
    "    os.chdir(ROOT)\n",
    "\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "print(\"Project root:\", ROOT)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Reproducibility helpers\n",
    "# -------------------------------------------------------------------\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "    \"\"\"Select best available device: CUDA, MPS (Apple), or CPU.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "DEVICE = get_device()\n",
    "print(\"Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b6fc53",
   "metadata": {},
   "source": [
    "## 2) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66a0a294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches:\n",
      "  train: 4096\n",
      "  val: 512\n",
      "  test: 512\n"
     ]
    }
   ],
   "source": [
    "from src.datasets.dataloaders import get_pcam_dataloaders\n",
    "\n",
    "# You can adjust batch_size and crop size if needed\n",
    "BATCH_SIZE = 64\n",
    "CENTER_CROP = 64\n",
    "\n",
    "loaders = get_pcam_dataloaders(\n",
    "    data_root=\"data/raw\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    center_crop_size=CENTER_CROP,\n",
    "    num_workers=0,  # 0 is safer on macOS / some environments\n",
    ")\n",
    "\n",
    "print(\"Number of batches:\")\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"  {split}: {len(loaders[split])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eec706",
   "metadata": {},
   "source": [
    "## 3) Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85a8e6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([64, 3, 64, 64])\n",
      "Labels shape: torch.Size([64])\n",
      "First 10 labels: tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 0])\n",
      "Label distribution in this batch: {0: 26, 1: 38}\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(loaders[\"train\"]))\n",
    "print(\"Images shape:\", images.shape)   # [B, 3, 64, 64]\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "print(\"First 10 labels:\", labels[:10])\n",
    "\n",
    "unique, counts = torch.unique(labels, return_counts=True)\n",
    "print(\"Label distribution in this batch:\", dict(zip(unique.tolist(), counts.tolist())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda40284",
   "metadata": {},
   "source": [
    "## 4) Import ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a2e75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode='frozen': trainable params = 513\n",
      "Mode='partial': trainable params = 8,394,241\n",
      "Mode='full': trainable params = 11,177,025\n"
     ]
    }
   ],
   "source": [
    "from src.models.resnet_pcam_gpu import ResNetPCam, ResNetConfig\n",
    "\n",
    "def count_trainable_params(model: torch.nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "for mode in [\"frozen\", \"partial\", \"full\"]:\n",
    "    cfg = ResNetConfig(tl_mode=mode, pretrained=True)\n",
    "    m = ResNetPCam(cfg)\n",
    "    print(\n",
    "        f\"Mode='{mode}': trainable params = {count_trainable_params(m):,}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb15353",
   "metadata": {},
   "source": [
    "## 5) Tuning Hyperparameters with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae21902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_tuning_dataloaders(\n",
    "    batch_size: int,\n",
    "    max_train_samples: int = 2000,\n",
    "    max_val_samples: int = 500,\n",
    "    center_crop_size: int = 64,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build smaller train/val dataloaders for hyperparameter tuning.\n",
    "\n",
    "    This uses a subset of the full train/val sets to keep each trial reasonably cheap.\n",
    "    \"\"\"\n",
    "    # We reuse the same underlying datasets that get_pcam_dataloaders uses.\n",
    "    full_loaders = get_pcam_dataloaders(\n",
    "        data_root=\"data/raw\",\n",
    "        batch_size=batch_size,\n",
    "        center_crop_size=center_crop_size,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    full_train_ds = full_loaders[\"train\"].dataset\n",
    "    full_val_ds = full_loaders[\"val\"].dataset\n",
    "\n",
    "    # Create deterministic random subsets for reproducibility\n",
    "    g = torch.Generator().manual_seed(42)\n",
    "\n",
    "    train_size = min(len(full_train_ds), max_train_samples)\n",
    "    val_size = min(len(full_val_ds), max_val_samples)\n",
    "\n",
    "    train_indices = torch.randperm(len(full_train_ds), generator=g)[:train_size]\n",
    "    val_indices = torch.randperm(len(full_val_ds), generator=g)[:val_size]\n",
    "\n",
    "    train_subset = Subset(full_train_ds, train_indices.tolist())\n",
    "    val_subset = Subset(full_val_ds, val_indices.tolist())\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Tuning loaders: train_samples={len(train_subset)}, \"\n",
    "        f\"val_samples={len(val_subset)}, batch_size={batch_size}\"\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5c548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from torch import nn, optim\n",
    "from src.training.utils_training import evaluate_binary_classifier\n",
    "\n",
    "def build_resnet_and_optimizer(\n",
    "    tl_mode: str,\n",
    "    lr: float,\n",
    "    weight_decay: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper to construct a ResNet model + optimizer + loss for a given trial.\n",
    "    \"\"\"\n",
    "    cfg = ResNetConfig(tl_mode=tl_mode, pretrained=True)\n",
    "    model = ResNetPCam(cfg).to(DEVICE)\n",
    "\n",
    "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(\n",
    "        trainable_params,\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    return model, optimizer, criterion\n",
    "\n",
    "\n",
    "\n",
    "# Fixed TL mode for the current study.\n",
    "# We will set this to \"frozen\" or \"partial\" before running a study.\n",
    "FIXED_TL_MODE = \"frozen\"  # will be overwritten below as needed\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Optuna objective function for ResNet18 on PCam.\n",
    "\n",
    "    We optimize validation AUROC (higher is better).\n",
    "    The transfer learning mode (tl_mode) is fixed per study (frozen / partial).\n",
    "    \"\"\"\n",
    "    tl_mode = FIXED_TL_MODE  # <-- NOT sampled, fixed for this study\n",
    "\n",
    "    # Hyperparameter search space (per mode)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 8e-4, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32])\n",
    "\n",
    "    # Smaller dataloaders for tuning\n",
    "    train_loader, val_loader = get_tuning_dataloaders(\n",
    "        batch_size=batch_size,\n",
    "        max_train_samples=2000,\n",
    "        max_val_samples=500,\n",
    "        center_crop_size=CENTER_CROP,\n",
    "    )\n",
    "\n",
    "    model, optimizer, criterion = build_resnet_and_optimizer(\n",
    "        tl_mode=tl_mode,\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    num_epochs = 2  # keep tuning epochs small\n",
    "    best_val_auroc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.float().to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        val_loss, val_auroc, val_auprc = evaluate_binary_classifier(\n",
    "            model, val_loader, criterion, DEVICE\n",
    "        )\n",
    "\n",
    "        trial.report(val_auroc, step=epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        best_val_auroc = max(best_val_auroc, val_auroc)\n",
    "\n",
    "        print(\n",
    "            f\"[trial {trial.number:02d} | mode={tl_mode}] \"\n",
    "            f\"epoch={epoch+1} lr={lr:.1e} wd={weight_decay:.1e} bs={batch_size} | \"\n",
    "            f\"val_AUROC={val_auroc:.3f}\"\n",
    "        )\n",
    "\n",
    "    return best_val_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af9096ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:36:24,934] A new study created in memory with name: resnet_pcam_frozen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Optuna study for tl_mode='frozen'\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=16\n",
      "[trial 00 | mode=frozen] epoch=1 lr=2.2e-04 wd=8.0e-04 bs=16 | val_AUROC=0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:36:52,522] Trial 0 finished with value: 0.7126940106067241 and parameters: {'lr': 0.0002178930765977573, 'weight_decay': 0.0007969454818643932, 'batch_size': 16}. Best is trial 0 with value: 0.7126940106067241.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 00 | mode=frozen] epoch=2 lr=2.2e-04 wd=8.0e-04 bs=16 | val_AUROC=0.713\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 01 | mode=frozen] epoch=1 lr=1.4e-04 wd=2.1e-05 bs=32 | val_AUROC=0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:37:19,188] Trial 1 finished with value: 0.6933943138876725 and parameters: {'lr': 0.00013832442448846117, 'weight_decay': 2.0511104188433963e-05, 'batch_size': 32}. Best is trial 0 with value: 0.7126940106067241.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 01 | mode=frozen] epoch=2 lr=1.4e-04 wd=2.1e-05 bs=32 | val_AUROC=0.693\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 02 | mode=frozen] epoch=1 lr=3.5e-04 wd=2.6e-04 bs=32 | val_AUROC=0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:37:42,888] Trial 2 finished with value: 0.7603431778004833 and parameters: {'lr': 0.0003490285460630004, 'weight_decay': 0.0002607024758370766, 'batch_size': 32}. Best is trial 2 with value: 0.7603431778004833.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 02 | mode=frozen] epoch=2 lr=3.5e-04 wd=2.6e-04 bs=32 | val_AUROC=0.760\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 03 | mode=frozen] epoch=1 lr=5.6e-04 wd=2.7e-05 bs=32 | val_AUROC=0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:38:05,857] Trial 3 finished with value: 0.8078463809014094 and parameters: {'lr': 0.0005646386642932582, 'weight_decay': 2.6587543983272695e-05, 'batch_size': 32}. Best is trial 3 with value: 0.8078463809014094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 03 | mode=frozen] epoch=2 lr=5.6e-04 wd=2.7e-05 bs=32 | val_AUROC=0.808\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=16\n",
      "[trial 04 | mode=frozen] epoch=1 lr=1.9e-04 wd=1.1e-04 bs=16 | val_AUROC=0.683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:38:31,086] Trial 4 finished with value: 0.7515042410678084 and parameters: {'lr': 0.00018826002986047262, 'weight_decay': 0.00011207606211860574, 'batch_size': 16}. Best is trial 3 with value: 0.8078463809014094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 04 | mode=frozen] epoch=2 lr=1.9e-04 wd=1.1e-04 bs=16 | val_AUROC=0.752\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 05 | mode=frozen] epoch=1 lr=3.6e-04 wd=1.9e-05 bs=32 | val_AUROC=0.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:38:53,866] Trial 5 finished with value: 0.7554777080393779 and parameters: {'lr': 0.0003569095943771273, 'weight_decay': 1.9010245319870364e-05, 'batch_size': 32}. Best is trial 3 with value: 0.8078463809014094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 05 | mode=frozen] epoch=2 lr=3.6e-04 wd=1.9e-05 bs=32 | val_AUROC=0.755\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 06 | mode=frozen] epoch=1 lr=2.6e-04 wd=3.7e-04 bs=32 | val_AUROC=0.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:39:16,898] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=16\n",
      "[trial 07 | mode=frozen] epoch=1 lr=3.4e-04 wd=1.2e-05 bs=16 | val_AUROC=0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:39:41,475] Trial 7 finished with value: 0.7963800904977376 and parameters: {'lr': 0.0003427706793941003, 'weight_decay': 1.2385137298860926e-05, 'batch_size': 16}. Best is trial 3 with value: 0.8078463809014094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 07 | mode=frozen] epoch=2 lr=3.4e-04 wd=1.2e-05 bs=16 | val_AUROC=0.796\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=16\n",
      "[trial 08 | mode=frozen] epoch=1 lr=1.1e-04 wd=7.9e-04 bs=16 | val_AUROC=0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:40:06,893] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=16\n",
      "[trial 09 | mode=frozen] epoch=1 lr=1.9e-04 wd=1.6e-05 bs=16 | val_AUROC=0.630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:40:32,452] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 10 | mode=frozen] epoch=1 lr=7.1e-04 wd=5.3e-05 bs=32 | val_AUROC=0.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:40:55,696] Trial 10 finished with value: 0.8155662595890301 and parameters: {'lr': 0.0007137454446124092, 'weight_decay': 5.3389437745561126e-05, 'batch_size': 32}. Best is trial 10 with value: 0.8155662595890301.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 10 | mode=frozen] epoch=2 lr=7.1e-04 wd=5.3e-05 bs=32 | val_AUROC=0.816\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 11 | mode=frozen] epoch=1 lr=7.2e-04 wd=4.9e-05 bs=32 | val_AUROC=0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:41:18,646] Trial 11 finished with value: 0.7960070711493862 and parameters: {'lr': 0.0007249712432705719, 'weight_decay': 4.9211947176147695e-05, 'batch_size': 32}. Best is trial 10 with value: 0.8155662595890301.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 11 | mode=frozen] epoch=2 lr=7.2e-04 wd=4.9e-05 bs=32 | val_AUROC=0.796\n",
      "Finished trials (frozen): 12\n",
      "Best AUROC (frozen): 0.8155662595890301\n",
      "Best params (frozen):\n",
      "  lr: 0.0007137454446124092\n",
      "  weight_decay: 5.3389437745561126e-05\n",
      "  batch_size: 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0007137454446124092,\n",
       " 'weight_decay': 5.3389437745561126e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIXED_TL_MODE = \"frozen\"\n",
    "print(\"Running Optuna study for tl_mode='frozen'\")\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=2, n_warmup_steps=1)\n",
    "\n",
    "study_frozen = optuna.create_study(\n",
    "    study_name=\"resnet_pcam_frozen\",\n",
    "    direction=\"maximize\",\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    ")\n",
    "\n",
    "study_frozen.optimize(objective, n_trials=12)  # increase later if you want\n",
    "\n",
    "print(\"Finished trials (frozen):\", len(study_frozen.trials))\n",
    "print(\"Best AUROC (frozen):\", study_frozen.best_trial.value)\n",
    "print(\"Best params (frozen):\")\n",
    "for k, v in study_frozen.best_trial.params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "best_params_frozen = study_frozen.best_trial.params\n",
    "best_params_frozen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6cb1374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:58:33,918] A new study created in memory with name: resnet_pcam_partial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Optuna study for tl_mode='partial'\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=16\n",
      "[trial 00 | mode=partial] epoch=1 lr=2.2e-04 wd=8.0e-04 bs=16 | val_AUROC=0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 09:59:33,898] Trial 0 finished with value: 0.862145023435346 and parameters: {'lr': 0.0002178930765977573, 'weight_decay': 0.0007969454818643932, 'batch_size': 16}. Best is trial 0 with value: 0.862145023435346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 00 | mode=partial] epoch=2 lr=2.2e-04 wd=8.0e-04 bs=16 | val_AUROC=0.862\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 01 | mode=partial] epoch=1 lr=1.4e-04 wd=2.1e-05 bs=32 | val_AUROC=0.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 10:00:18,683] Trial 1 finished with value: 0.8780551095541609 and parameters: {'lr': 0.00013832442448846117, 'weight_decay': 2.0511104188433963e-05, 'batch_size': 32}. Best is trial 1 with value: 0.8780551095541609.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 01 | mode=partial] epoch=2 lr=1.4e-04 wd=2.1e-05 bs=32 | val_AUROC=0.878\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 02 | mode=partial] epoch=1 lr=3.5e-04 wd=2.6e-04 bs=32 | val_AUROC=0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 10:01:01,726] Trial 2 finished with value: 0.8887591430285927 and parameters: {'lr': 0.0003490285460630004, 'weight_decay': 0.0002607024758370766, 'batch_size': 32}. Best is trial 2 with value: 0.8887591430285927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 02 | mode=partial] epoch=2 lr=3.5e-04 wd=2.6e-04 bs=32 | val_AUROC=0.889\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 03 | mode=partial] epoch=1 lr=5.6e-04 wd=2.7e-05 bs=32 | val_AUROC=0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 10:01:47,523] Trial 3 finished with value: 0.8963979305535283 and parameters: {'lr': 0.0005646386642932582, 'weight_decay': 2.6587543983272695e-05, 'batch_size': 32}. Best is trial 3 with value: 0.8963979305535283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 03 | mode=partial] epoch=2 lr=5.6e-04 wd=2.7e-05 bs=32 | val_AUROC=0.896\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=16\n",
      "[trial 04 | mode=partial] epoch=1 lr=1.9e-04 wd=1.1e-04 bs=16 | val_AUROC=0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 10:02:48,473] Trial 4 finished with value: 0.8859533887996885 and parameters: {'lr': 0.00018826002986047262, 'weight_decay': 0.00011207606211860574, 'batch_size': 16}. Best is trial 3 with value: 0.8963979305535283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 04 | mode=partial] epoch=2 lr=1.9e-04 wd=1.1e-04 bs=16 | val_AUROC=0.886\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 05 | mode=partial] epoch=1 lr=3.6e-04 wd=1.9e-05 bs=32 | val_AUROC=0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 10:03:31,730] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 06 | mode=partial] epoch=1 lr=2.6e-04 wd=3.7e-04 bs=32 | val_AUROC=0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 10:04:15,033] Trial 6 finished with value: 0.8893592176324625 and parameters: {'lr': 0.00025815006344207555, 'weight_decay': 0.00037183641805732076, 'batch_size': 32}. Best is trial 3 with value: 0.8963979305535283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 06 | mode=partial] epoch=2 lr=2.6e-04 wd=3.7e-04 bs=32 | val_AUROC=0.886\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=16\n",
      "[trial 07 | mode=partial] epoch=1 lr=3.4e-04 wd=1.2e-05 bs=16 | val_AUROC=0.861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 10:05:15,169] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=16\n",
      "[trial 08 | mode=partial] epoch=1 lr=1.1e-04 wd=7.9e-04 bs=16 | val_AUROC=0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 10:06:15,112] Trial 8 finished with value: 0.8896187093530548 and parameters: {'lr': 0.00011448469784568747, 'weight_decay': 0.000790261954970823, 'batch_size': 16}. Best is trial 3 with value: 0.8963979305535283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 08 | mode=partial] epoch=2 lr=1.1e-04 wd=7.9e-04 bs=16 | val_AUROC=0.890\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=16\n",
      "[trial 09 | mode=partial] epoch=1 lr=1.9e-04 wd=1.6e-05 bs=16 | val_AUROC=0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 10:07:15,328] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=32\n",
      "[trial 10 | mode=partial] epoch=1 lr=7.1e-04 wd=5.3e-05 bs=32 | val_AUROC=0.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 10:07:59,208] Trial 10 finished with value: 0.8870724468447428 and parameters: {'lr': 0.0007137454446124092, 'weight_decay': 5.3389437745561126e-05, 'batch_size': 32}. Best is trial 3 with value: 0.8963979305535283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trial 10 | mode=partial] epoch=2 lr=7.1e-04 wd=5.3e-05 bs=32 | val_AUROC=0.887\n",
      "Tuning loaders: train_samples=2000, val_samples=500, batch_size=16\n",
      "[trial 11 | mode=partial] epoch=1 lr=1.0e-04 wd=5.6e-05 bs=16 | val_AUROC=0.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-14 10:09:00,537] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trials (partial): 12\n",
      "Best AUROC (partial): 0.8963979305535283\n",
      "Best params (partial):\n",
      "  lr: 0.0005646386642932582\n",
      "  weight_decay: 2.6587543983272695e-05\n",
      "  batch_size: 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0005646386642932582,\n",
       " 'weight_decay': 2.6587543983272695e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIXED_TL_MODE = \"partial\"\n",
    "print(\"\\nRunning Optuna study for tl_mode='partial'\")\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=2, n_warmup_steps=1)\n",
    "\n",
    "study_partial = optuna.create_study(\n",
    "    study_name=\"resnet_pcam_partial\",\n",
    "    direction=\"maximize\",\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    ")\n",
    "\n",
    "study_partial.optimize(objective, n_trials=12)  # same budget as frozen\n",
    "\n",
    "print(\"Finished trials (partial):\", len(study_partial.trials))\n",
    "print(\"Best AUROC (partial):\", study_partial.best_trial.value)\n",
    "print(\"Best params (partial):\")\n",
    "for k, v in study_partial.best_trial.params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "best_params_partial = study_partial.best_trial.params\n",
    "best_params_partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c4d837",
   "metadata": {},
   "source": [
    "## 5) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c895d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from src.training.utils_training import evaluate_binary_classifier\n",
    "\n",
    "NUM_WORKERS = min(8, os.cpu_count()-1)\n",
    "BATCH_FINAL = 64 \n",
    "EPOCHS_FINAL = 20\n",
    "use_amp = True\n",
    "patience = 2\n",
    "BATCH_EVAL = 256\n",
    "\n",
    "\n",
    "def train_resnet_one_mode(\n",
    "    tl_mode: str,\n",
    "    num_epochs: int = 2,\n",
    "    lr: float = 1e-4,\n",
    "    weight_decay: float = 1e-5,\n",
    "    batch_size: int = 64,\n",
    "    max_train_batches: int | None = None,\n",
    "    dropout_p: float = 0.0,\n",
    "    patience: int = 2,\n",
    "    use_scheduler: bool = True,\n",
    "    use_amp: bool = True,\n",
    "    num_workers: int = 0,\n",
    "    ckpt_dir: str | Path = \"experiments/runs\",\n",
    "    save_every: int = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a ResNetPCam model for a given transfer learning mode (GPUâ€‘ready).\n",
    "\n",
    "    Adds AMP (if available), configurable num_workers, periodic checkpointing, and\n",
    "    saving of both best-by-val-loss and best-by-AUROC model states.\n",
    "    \"\"\"\n",
    "    ckpt_dir = Path(ckpt_dir)\n",
    "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"=== Training ResNet18 with tl_mode='{tl_mode}' (num_workers={num_workers}, AMP={use_amp}) ===\")\n",
    "    # reload dataloaders in case batch_size differs\n",
    "    loaders_local = get_pcam_dataloaders(\n",
    "        data_root=\"data/raw\",\n",
    "        batch_size=batch_size,\n",
    "        center_crop_size=CENTER_CROP,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    cfg = ResNetConfig(tl_mode=tl_mode, pretrained=True, dropout_p=dropout_p)\n",
    "    model = ResNetPCam(cfg).to(DEVICE)\n",
    "\n",
    "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    print(\"Trainable parameters:\", f\"{sum(p.numel() for p in trainable_params):,}\")\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        trainable_params,\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "    scheduler = (\n",
    "        ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1, verbose=True)\n",
    "        if use_scheduler\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler() if (use_amp and DEVICE.type == \"cuda\") else None\n",
    "\n",
    "    history = []\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_state = None\n",
    "    best_val_auroc = float(\"-inf\")\n",
    "    best_state_auroc = None\n",
    "    bad_epochs = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(loaders_local[\"train\"]):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.float().to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scaler is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    logits = model(images)\n",
    "                    loss = criterion(logits, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                logits = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "            if max_train_batches is not None and (batch_idx + 1) >= max_train_batches:\n",
    "                break\n",
    "\n",
    "        # If we cut off early, approximate the effective dataset size\n",
    "        if max_train_batches is not None:\n",
    "            effective_size = max_train_batches * batch_size\n",
    "        else:\n",
    "            effective_size = len(loaders_local[\"train\"].dataset)\n",
    "\n",
    "        train_loss /= effective_size\n",
    "\n",
    "        val_loss, val_auroc, val_auprc = evaluate_binary_classifier(\n",
    "            model, loaders_local[\"val\"], criterion, DEVICE\n",
    "        )\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        history.append(\n",
    "            dict(\n",
    "                epoch=epoch,\n",
    "                train_loss=train_loss,\n",
    "                val_loss=val_loss,\n",
    "                val_auroc=val_auroc,\n",
    "                val_auprc=val_auprc,\n",
    "                lr=optimizer.param_groups[0][\"lr\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # best by val loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            # save best-by-val-loss\n",
    "            torch.save(best_state, ckpt_dir / f\"resnet_best_by_val_loss_{tl_mode}.pt\")\n",
    "            bad_epochs = 0\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "\n",
    "        # best by AUROC\n",
    "        if val_auroc is not None and val_auroc > best_val_auroc:\n",
    "            best_val_auroc = val_auroc\n",
    "            best_state_auroc = model.state_dict()\n",
    "            torch.save(best_state_auroc, ckpt_dir / f\"resnet_best_by_auroc_{tl_mode}.pt\")\n",
    "\n",
    "        # periodic checkpoint\n",
    "        if epoch % save_every == 0:\n",
    "            ckpt = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"opt\": optimizer.state_dict(),\n",
    "                \"scaler\": scaler.state_dict() if scaler is not None else None,\n",
    "                \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                \"val_loss\": float(val_loss),\n",
    "                \"val_auroc\": float(val_auroc),\n",
    "                \"val_auprc\": float(val_auprc),\n",
    "            }\n",
    "            torch.save(ckpt, ckpt_dir / f\"resnet_ckpt_epoch{epoch}_{tl_mode}.pt\")\n",
    "\n",
    "        print(\n",
    "            f\"[{tl_mode}] Epoch {epoch:02d} | \"\n",
    "            f\"train_loss={train_loss:.4f} | \"\n",
    "            f\"val_loss={val_loss:.4f} | \"\n",
    "            f\"AUROC={val_auroc:.3f} | \"\n",
    "            f\"AUPRC={val_auprc:.3f} | \"\n",
    "            f\"lr={optimizer.param_groups[0]['lr']:.2e}\"\n",
    "        )\n",
    "\n",
    "        if bad_epochs > patience:\n",
    "            print(f\"Early stopping at epoch {epoch} (no val improvement for {bad_epochs} epochs)\")\n",
    "            break\n",
    "\n",
    "    # Load best state (val-loss) into model before returning\n",
    "    if best_state is not None:\n",
    "\n",
    "        model.load_state_dict(best_state)    return model, history, best_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20661e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training ResNet18 with tl_mode='partial' ===\n",
      "Trainable parameters: 8,394,241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch312/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[partial] Epoch 01 | train_loss=0.3487 | val_loss=0.3570 | AUROC=0.924 | AUPRC=0.925 | lr=5.65e-04\n",
      "[partial] Epoch 02 | train_loss=0.3041 | val_loss=0.3730 | AUROC=0.919 | AUPRC=0.923 | lr=5.65e-04\n",
      "[partial] Epoch 03 | train_loss=0.2866 | val_loss=0.3967 | AUROC=0.913 | AUPRC=0.919 | lr=2.82e-04\n",
      "[partial] Epoch 04 | train_loss=0.2615 | val_loss=0.4018 | AUROC=0.916 | AUPRC=0.922 | lr=2.82e-04\n",
      "Early stopping at epoch 4 (no val improvement for 3 epochs)\n",
      "[partial] Test metrics | loss=0.4819 | AUROC=0.894 | AUPRC=0.898\n"
     ]
    }
   ],
   "source": [
    "# Final training/eval with best partial params on full data\n",
    "from torch import nn\n",
    "from importlib import reload\n",
    "import src.models.resnet_pcam_gpu as resnet_module\n",
    "\n",
    "reload(resnet_module)  # picks up the updated ResNetConfig/ResNetPCam\n",
    "ResNetConfig = resnet_module.ResNetConfig\n",
    "ResNetPCam = resnet_module.ResNetPCam\n",
    "\n",
    "# Use best partial params from Optuna\n",
    "FINAL_TL_MODE = \"partial\"\n",
    "FINAL_EPOCHS = 12  # longer run for GPU\n",
    "FINAL_DROPOUT = 0.0\n",
    "\n",
    "\n",
    "resnet_partial_final, hist_partial_final, best_state_partial = train_resnet_one_mode(\n",
    "    tl_mode=FINAL_TL_MODE,\n",
    "    num_epochs=FINAL_EPOCHS,\n",
    "    lr=best_params_partial[\"lr\"],\n",
    "    weight_decay=best_params_partial[\"weight_decay\"],\n",
    "    batch_size=best_params_partial[\"batch_size\"],\n",
    "    dropout_p=FINAL_DROPOUT,\n",
    "    max_train_batches=None,  # full epochs\n",
    "    use_amp=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    ckpt_dir=Path(\"experiments/runs\"),\n",
    "    save_every=1,\n",
    ")\n",
    "\n",
    "# Evaluate on test split\n",
    "loaders_eval = get_pcam_dataloaders(\n",
    "    data_root=\"data/raw\",\n",
    "    batch_size=best_params_partial[\"batch_size\"],\n",
    "    center_crop_size=CENTER_CROP,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "test_loss, test_auroc, test_auprc = evaluate_binary_classifier(\n",
    "    resnet_partial_final,\n",
    "    loaders_eval[\"test\"],\n",
    "    criterion,\n",
    "    DEVICE,\n",
    ")\n",
    "\n",
    "print(\n",
    "\n",
    "    f\"[partial] Test metrics | loss={test_loss:.4f} | AUROC={test_auroc:.3f} | AUPRC={test_auprc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training ResNet18 with tl_mode='frozen' ===\n",
      "Trainable parameters: 513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch312/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[frozen] Epoch 01 | train_loss=0.4969 | val_loss=0.4915 | AUROC=0.847 | AUPRC=0.840 | lr=7.14e-04\n",
      "[frozen] Epoch 02 | train_loss=0.4919 | val_loss=0.4745 | AUROC=0.858 | AUPRC=0.849 | lr=7.14e-04\n",
      "[frozen] Epoch 03 | train_loss=0.4904 | val_loss=0.4846 | AUROC=0.852 | AUPRC=0.842 | lr=7.14e-04\n",
      "[frozen] Epoch 04 | train_loss=0.4887 | val_loss=0.4717 | AUROC=0.860 | AUPRC=0.853 | lr=7.14e-04\n",
      "[frozen] Epoch 05 | train_loss=0.4890 | val_loss=0.4793 | AUROC=0.856 | AUPRC=0.845 | lr=7.14e-04\n",
      "[frozen] Epoch 06 | train_loss=0.4900 | val_loss=0.4711 | AUROC=0.860 | AUPRC=0.854 | lr=7.14e-04\n",
      "[frozen] Epoch 07 | train_loss=0.4899 | val_loss=0.4790 | AUROC=0.858 | AUPRC=0.848 | lr=7.14e-04\n",
      "[frozen] Epoch 08 | train_loss=0.4898 | val_loss=0.4848 | AUROC=0.851 | AUPRC=0.844 | lr=3.57e-04\n",
      "[frozen] Test metrics | loss=0.5127 | AUROC=0.833 | AUPRC=0.827\n"
     ]
    }
   ],
   "source": [
    "# Final training/eval with best frozen params on full data\n",
    "from torch import nn\n",
    "\n",
    "FINAL_TL_MODE_FROZEN = \"frozen\"\n",
    "FINAL_EPOCHS_FROZEN = 12\n",
    "FINAL_DROPOUT_FROZEN = 0.0\n",
    "\n",
    "resnet_frozen_final, hist_frozen_final, best_state_frozen = train_resnet_one_mode(\n",
    "    tl_mode=FINAL_TL_MODE_FROZEN,\n",
    "    num_epochs=FINAL_EPOCHS_FROZEN,\n",
    "    lr=best_params_frozen[\"lr\"],\n",
    "    weight_decay=best_params_frozen[\"weight_decay\"],\n",
    "    batch_size=best_params_frozen[\"batch_size\"],\n",
    "    dropout_p=FINAL_DROPOUT_FROZEN,\n",
    "    max_train_batches=None,\n",
    "    use_amp=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    ckpt_dir=Path(\"experiments/runs\"),\n",
    "    save_every=1,\n",
    ")\n",
    "\n",
    "loaders_eval_frozen = get_pcam_dataloaders(\n",
    "    data_root=\"data/raw\",\n",
    "    batch_size=best_params_frozen[\"batch_size\"],\n",
    "    center_crop_size=CENTER_CROP,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "test_loss, test_auroc, test_auprc = evaluate_binary_classifier(\n",
    "    resnet_frozen_final,\n",
    "    loaders_eval_frozen[\"test\"],\n",
    "    criterion,\n",
    "    DEVICE,\n",
    ")\n",
    "\n",
    "print(\n",
    "\n",
    "    f\"[frozen] Test metrics | loss={test_loss:.4f} | AUROC={test_auroc:.3f} | AUPRC={test_auprc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
